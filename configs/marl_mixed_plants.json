{
  "system": {
    "n_agents": 3,
    "A": [[0.99, 0.01], [0.0, 0.99]],
    "B": [[0.000025], [0.005]],
    "heterogeneous_plants": [
      { "A": [[0.98, 0.01], [0.0, 0.995]], "B": [[0.00002], [0.004]] },
      { "A": [[0.965, 0.01], [0.0, 0.98]], "B": [[0.00003], [0.006]] },
      { "A": [[0.992, 0.01], [0.0, 0.985]], "B": [[0.000027], [0.0055]] }
    ],
    "process_noise_cov": [[0.1, 0.0], [0.0, 0.1]],
    "measurement_noise_cov": [[0.0, 0.0], [0.0, 0.0]],
    "initial_estimate_cov": [[1.0, 0.0], [0.0, 1.0]],
    "initial_state_scale_min": 0.9,
    "initial_state_scale_max": 1.0
  },
  "lqr": {
    "Q": [[1.0, 0.0], [0.0, 1.0]],
    "R": [[0.1]]
  },
  "reward": {
    "state_cost_matrix": [[1.0, 0.0], [0.0, 1.0]],
    "comm_recent_window": 10,
    "comm_throughput_window": 200,
    "comm_penalty_alpha": 0.0,
    "comm_throughput_floor": 0.0,
    "normalization_type": "running",
    "reward_mixing": {
      "enabled": true,
      "rewards": [
        { "state_error_reward": "simple_penalty", "simple_comm_penalty_alpha": 0.0 },
        { "state_error_reward": "absolute", "normalize": true }
      ],
      "scheduler": {
        "type": "linear",
        "start_value": 1.0,
        "end_value": 0.95,
        "total_steps": 600000
      }
    },
    "evaluation": {
      "state_error_reward": "absolute",
      "comm_penalty_alpha": 0.0,
      "simple_comm_penalty_alpha": 0.0,
      "normalize": false,
      "reward_mixing": {
        "enabled": false
      }
    }
  },
  "observation": {
    "history_window": 10,
    "state_history_window": 10,
    "throughput_window": 50,
    "quantization_step": 0
  },
  "network": {
    "data_rate_kbps": 125.0,
    "data_packet_size": 100,
    "ack_packet_size": 2,
    "max_queue_size": 1,
    "perfect_communication": false
  }
}
